\chapter{Vorstellung von Apache Spark}
Aus Sicht eines Nutzers ist Apache Spark eine API zum Zugriff auf Daten und deren Verarbeitung.\\

Diese API (wahlweise für die Programmiersprachen Scala, Java und Python verfügbar), kann im einfachsten Fall über eine eigene Spark Konsole mit \gls{repl}\cite{Hail} verwendet werden.\\
Die Zählung von Wortvorkommen in einem Text - das "`Hello World"' der Big Data Szene - lässt sich dort mit zwei Befehlen realisieren (Listing \ref{lst:sconsole_wordcount}).\\

\begin{lstlisting}[caption={Word Count in der Spark Konsole},label={lst:sconsole_wordcount}]
my_dollar ./spark-shell
[...]
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.3.0
      /_/
Using Scala version 2.10.4 (OpenJDK 64-Bit Server VM, Java 1.7.0_75)
Type in expressions to have them evaluated.
[...]
scala> val text = sc.textFile("../Heinrich Heine - Der Ex-Lebendige")
[...]
scala> :paste
text.flatMap(line => line.split(" "))
.map(word => (word, 1))
.reduceByKey(_ + _)
.collect()
[...]
res0: Array[(String, Int)] = Array((Tyrann,,1), (im,2), (Doch,1) ...)
\end{lstlisting}


Aus Sicht eines Administrators oder Softwarearchitekten ist Apache Spark eine Applikation auf einem \gls{cluster}, die sich in der Anwendungsschicht befindet und charakteristische Anforderungen insbesondere an Lokalität des Storages und die Netzwerkperformance stellt.\\

Was das konkret bedeutet, welche Mechanismen und Konzepte dahinterstehen und in welchem Ökosystem von Anwendungen sich Apache Spark bewegt wird in den folgenden Abschnitten dieses Kapitels beleuchtet.

\section{Überblick}
Im Allgemeinen Fall läuft eine Spark-Anwendung auf drei Arten von Rechnern (s. Abb.~\ref{fig:sparkdeployment}):

\begin{enumerate}
	\item \textbf{Clientknoten}\\
	Auf Nutzerseite greift die Anwendung auf die API eines lokalen Spark-Kontextes zu, der die Kontaktdaten eines Clustermanagers sowie verschiedene Konfigurationseinstellungen enthält. 
	
	\item \textbf{\gls{master}knoten}\\
	Der \gls{master}knoten betreibt den \textit{Clustermanager}, läuft auf einem entfernten Rechner und ist der Einstiegspunkt in den \gls{cluster}. Hier werden Aufträge des Anwenders an die Arbeitsknoten verteilt und Ergebnisse eingesammelt und zurückgereicht.
	
	\item \textbf{\gls{worker}knoten}\\
	Die \gls{worker}knoten beherbergen die Spark \textit{Executors} und sind die ausführenden Elemente der Aktionen und Transformationen. Die \textit{Executors} können untereinander Zwischenergebnisse austauschen und melden ihre Ressourcenverfügbarkeit an den \textit{Clustermanager}.
\end{enumerate}

\begin{figure}[ht!]
	\centering
  \includegraphics[scale=0.7]{sparkdeployment2.pdf}
	\caption{Verteilungsdiagramm einer typischen Sparkinstallation}
	\label{fig:sparkdeployment}
\end{figure}

Um die Architektur und Optimierungskonzepte eines verteilten Systems bewerten zu können ist es offensichtlich wichtig, welche Eigenschaften der unterliegenden Hardware angenommen werden.

Weil Spark explizit für den Betrieb innerhalb eines Hadoop/YARN \textcolor{red}{[VERWEIS auf Abschnitt Scheduling]} geeignet ist und YARN wiederum für den Betrieb auf einem \gls{cluster} auf Mittelklasse-Mehrzweckmaschinen (Commodity Hardware) optimiert ist\cite{Mer14}, kann für Spark von einer vergleichbaren Hardwarekonfiguration ausgegangen werden.\\

Der Vergleich von drei aktuellen Rack Servern der 2000-Euro-Klasse (in der Grundausstattung) - hier als Mittelklasse-Geräte bezeichnet - liefert die folgenden Verhältnisse der wesentlichen Schnittstellen zueinander (Siehe Anhang~\ref{subsec:commodity_servers}).

\begin{table}[ht]
	\centering % used for centering table
	\begin{tabular}{c c c} % centered columns (4 columns)	
		\hline\hline %inserts double horizontal lines
		Netzwerk & Festspeicher & Arbeitsspeicher\\ [0.5ex] % inserts table
		%heading
		\hline % inserts single horizontal line
		0,125 GB/s & 1 GB/s & 17 GB/s \\ % inserting body of the table
		\hline %inserts single line
	\end{tabular}
	\caption{Theoretische Spitzenleistungen bei Mittelklasse-Servern} % title of Table
	\label{table:vgldurchsatz} % is used to refer this table in the text
\end{table}

Auf eine detaillierte Analyse des Zugriffsverhaltens wird im Rahmen dieser Arbeit verzichtet. Bei den folgenden Bewertungen der Kernkonzepte ist es wichtig sich die aus Tabelle \ref{table:vgldurchsatz} abgeleiteten Größenordnungen des Durchsatzes (\textit{D}) der verschiedenen Datenkanäle zu vergegenwärtigen:

\begin{equation*}
	D_{Netzwerk} < D_{Festspeicher} < D_{Arbeitsspeicher}
\end{equation*}

Für eine effiziente Verarbeitung von Daten ist es - ganz allgemein - also wünschenswert den größten Anteil des Datentransfers im Arbeitsspeicher zu haben, einen kleineren Anteil auf der Festplatte und einen noch kleineren Anteil auf Netzwerkverbindungen.\\

Es ist das wichtigste Ziel der folgenden Kernkonzepte von Apache Spark unter diesen Bedingungen die effiziente und stabile Verarbeitung \textit{großer Datenmengen}\cite{Sam14} zu gewährleisten.\\

\section{Kernkonzepte}

\subsection{Resilient Distributed Datasets}
Die universelle Einheit mit der ein Datenelement auf Spark repräsentiert wird ist ein sogenanntes \gls{rdd}\cite{Mat12}.\\

Ein Beispiel für ein solches \gls{rdd} wurde bereits erwähnt, nämlich das in Listing \ref{lst:sconsole_wordcount} erzeugte Objekt \lstinline|text|:\\

\begin{lstlisting}
val text = sc.textFile("../Heinrich Heine - Der Ex-Lebendige")
\end{lstlisting}

\Glspl{rdd} können auch explizit erzeugt werden, ohne dass dazu vorhandene Daten genutzt werden:\\

\begin{lstlisting}
val list = sc.parallelize(List(1,2,3,4,5,6))
\end{lstlisting}

Die gesamte operative Kern-\gls{api} dreht sich um die Steuerung dieser Dateneinheiten. Insbesondere sind auch die in den Standardbibliotheken verfügbaren "`höheren"' \glspl{api} auf diesen \glspl{rdd} implementiert.

Sie sind damit die wichtigste Abstraktion des Applikationskerns.\\

In erster Näherung können \glspl{rdd} als eine Variante von \gls{dsm}\cite{Nitzberg:1991:DSM:112827.112855} \cite{Mat12} verstanden werden, haben allerdings sehr charakteristische Einschränkungen und Erweiterungen, die in diesem Kapitel erläutert werden.\\

\paragraph{Verteilungssicht}\\

Aus Verteilungssicht ist ein \gls{rdd} ein Datensatz, der über den Arbeitsspeicher mehrerer Maschinen partitioniert ist (Abb.~\ref{fig:rdds1}).

\begin{figure}[ht!]
	\centering
  \includegraphics[scale=0.7]{RDDs1.pdf}
	\caption{Resilient Distributed Datasets aus Verteilungssicht}
	\label{fig:rdds1}
\end{figure}

\paragraph{Laufzeitsicht}\\

\Glspl{rdd} sind nicht veränderbar. Anstatt durch feingranulare Schreiboperationen modifiziert zu werden ist es nur möglich ein einmal definiertes \gls{rdd} durch globale Anwendung von Operationen in ein anderes zu überführen.\\

Diese Folge von Operationen $op_1op_2op_3...$ wird als \textit{Lineage} eines \gls{rdd} bezeichnet. Die \textit{Lineage} kann als das "`Rezept"' zur Erstellung eines Datensatzes verstanden werden.

Dabei gibt es zwei grundsätzlich verschiedene Operationen, nämlich \textit{Transformationen} und \textit{Aktionen}.\\

\textbf{\textit{Transformationen}} sind ... \\

\textbf{\textit{Aktionen}} sind ... \\

Solange nur \textit{Transformationen} auf einem \gls{rdd} ausgeführt werden, ist dieses noch ein bloßes "`Rezept"' zur Erstellung eines Datensatzes. Tatsächlich wurde noch kein Speicher reserviert und der Cluster wurde noch nicht aktiv\cite{Mat12}:\\

\begin{figure}[ht!]
	\centering
  \includegraphics[scale=0.8]{rdds_no_action.pdf}
	\caption{RDD Lineage vor Aktion}
	\label{fig:rdds_no_action}
\end{figure}

Sobald die erste \textit{Aktion} aufgerufen wird, werden die Transformationen nach der vorgegebenen Reihenfolge ausgeführt und die geforderte \textit{Aktion} ausgeführt:\\

\begin{figure}[ht!]
	\centering
  \includegraphics[scale=0.8]{rdds_action.pdf}
	\caption{RDD Lineage nach Aktion}
	\label{fig:rdds_action}
\end{figure}

Wie in Abb. \ref{fig:rdds_action} zu erkennen, werden während der Transformationsvorgänge keine Zwischenergebnisse gespeichert. Möchte Zwischenergebnisse zu einem späteren Zeitpunkt oder in anderem Zusammenhang wiederverwenden, kann man dies explizit über das Kommando \lstinline|persist()| anweisen:\\

\begin{figure}[ht!]
	\centering
  \includegraphics[scale=0.8]{rdds_action_persist.pdf}
	\caption{RDD Lineage nach Aktion und mit Persist()}
	\label{fig:rdds_action_persist}
\end{figure}


Ein möglicher Vorteil dieser Art von Arbeitsdatensatz wird sofort deutlich: Im optimalen Fall sind die zu ladenden Daten von jedem der \gls{worker} auf unabhängigen Kanälen erreichbar (z.B. auf dem lokalen Festspeicher) und gleichmäßig auf diesen Kanälen partitioniert.

\begin{figure}[h!]
	\centering
  \includegraphics[scale=0.7]{RDDs2.pdf}
	\caption{Resilient Distributed Datasets mit Datenquelle aus Verteilungssicht}
	\label{fig:rdds2}
\end{figure}

Im diesem Fall ergäbe sich mit einer Anzahl \gls{worker} $n$ und einem Durchsatz $\delta$ zu der jeweiligen Datenquelle also ein Gesamtdurchsatz beim Einlesen von Daten von:

\begin{equation}
	\sum_{i=1}^{n} \delta_i
\end{equation}


\subsection{Scheduling/Shuffling}

\subsection{Anwendungsdeployment und -lebenszyklus}

\paragraph{Anwendungsdeployment}\\

Die Komponente einer Anwendung, die von der Spark API Gebrauch macht wird in der Spark-Terminologie als \textit{Treiberprogramm} bezeichnet. \\

Es gibt verschiedene Szenarien des Deployments. Das Treiberprogramm kann grundsätzlich auf zwei verschiedene Arten gestartet werden:\\

\begin{enumerate}
	\item Übermittlung des Treibers als kompiliertes Package (z.B. als \gls{jarfile}) mit statischer Verlinkung aller erforderlichen Bibliotheken (Ausnahmen sind Bibliotheken die auf allen Knoten bereits verfügbar sind, z.B. Spark, Hadoop, etc.). Standardbibiotheken von Spark und Konfigurationseinstellungen wie z.B. die Angabe des \textit{Clustermanagers} können zur Startzeit des Treibers durch das Spark \textit{Submission-Skript} erfolgen.
	\item Start eines eigenständig lauffähigen Treibers mit vollständig konfigurierter und verlinkter Spark-Umgebung und expliziter Angabe eines \textit{Clustermanagers}.
\end{enumerate}

Der zweite Fall ist eher exotisch, weil eine derart enge Kopplung zwischen dem Treiber und der Konfiguration des Clusters offensichtlich aus Wartungsgründen nicht wünschenswert ist.\\

Im ersten Fall ergeben sich zwei weitere Möglichkeiten zum Ort der Ausführung des Treibers:\\

\begin{enumerate}
	\item \textbf{Client-Modus}	Der Treiber wird direkt auf dem Host (Gateway-Rechner) ausgeführt auf dem der Treiber übermittelt wurde (Abb.~\ref{fig:spark_deployment_clientmode}). Tatsächlich wird er sogar innerhalb des Submission-Skript-Prozesses gestartet \textbf{(VERWEIS)}.
	\item \textbf{Cluster-Modus}	Der Treiber wird von dem Gateway-Rechner an \gls{worker} des Clusters übertragen und dort ausgeführt (Abb.~\ref{fig:spark_deployment_clustermode}).
\end{enumerate}

\begin{figure}[ht!]
	\centering
  \includegraphics[scale=0.62]{spark_deployment_clientmode.pdf}
	\caption{Application Deployment im Client Modus}
	\label{fig:spark_deployment_clientmode}
\end{figure}

\begin{figure}[ht!]
	\centering
  \includegraphics[scale=0.62]{spark_deployment_clustermode.pdf}
	\caption{Application Deployment im Cluster Modus}
	\label{fig:spark_deployment_clustermode}
\end{figure}

Offensichtlich kann die Lokalität des Treibers (der mit den Executors auf den \gls{worker}n kommunizieren muss) Einfluss auf Laufzeit und Latenzverhalten des Programms haben.\\

Im Fall eines clusterfernen Gateway-Rechners kann also Treiberdeployment im Clustermodus sinnvoll sein, die Standardeinstellung ist jedoch der Clientmodus (siehe auch \cite{spark_submission}).\\

Abb.~\ref{fig:app_deployment_process} zeigt das Sequenzdiagramm eines typischen Deploymentprozesses, wie er auch im praktischen Teil dieser Arbeit zum Einsatz kommt.

\begin{figure}[ht!]
	\centering
  \includegraphics[scale=0.7]{spark_deployment_process.pdf}
	\caption{Application Deployment Prozess im Client Modus (vereinfacht)}
	\label{fig:app_deployment_process}
\end{figure}

\paragraph{Lebenszyklus einer Spark-Applikation}

\textcolor{gray}{Beginn und End eines Treiberprogramms. Beginn un Ende eines Tasks / Executorallokation?}\\

\subsection{Zusammenfassung und Bewertung}

\section{Standardbibliotheken}
\textcolor{gray}{--- Warum ist Spark so einfach (und wo vielleicht nicht)? ---}\\
Die vier Standardbibliotheken erweitern die Kern-API für bestimmte, häufig genutzte Aufgaben aus Bereichen der Datenanalyse.\\

Die bedienten Bereiche
\begin{itemize}
	\item Deklaratives Abfragen auf strukturierten Datensätzen (\textit{Spark SQL})
	\item Maschinenlernverfahren (\textit{MLlib})
	\item Echtzeitbehandlung von eingehenden Daten (\textit{Streaming})
	\item Operationen auf Graph-Strukturen (\textit{GraphX})
\end{itemize}
werden in diesem Abschnitt erläutert.

\subsection{Dataframes/Spark SQL}


\subsection{MLlib}
\subsection{Streaming}
\subsection{GraphX}

\section{Betrieb und Security}

\section{Spark im Kontext von Parallelisierungspattern}
\textcolor{gray}{--- Buch: Algorithms and Parallel Computing ---}\\

\section{Entwicklergemeinschaft}
\textcolor{gray}{--- Herkunft, Apache Foundation, Entwicklungsphilosophien, Anzahl Entwickler, ... ---}\\

Apache Spark begann als Entwicklung einer Gruppe von Forschern der University of California, Berkely. Spark ist eine Implementation der von dieser Gruppe untersuchten \glspl{rdd}\cite{Mat12}. Als wesentlicher Meilenstein der Entwicklung von Apache Spark, kann die Veröffentlichung eines gemeinsamen Papers der Forschungsgruppe um Matei Zaharia im Jahr 2012 gelten.\\

Seit dem 27. Februar 2014\cite{apacheblog} ist Spark ein Top-Level Projekt der Apache Software Foundation\cite{apache} und wird dort unter der Apache License 2.0\cite{apachelic} weiterentwickelt.\\

Eine Übersicht der verantwortlichen Committer kann unter \cite{committer} eingesehen werden.
Zum Zeitpunkt dieser Arbeit gehören u.a. Entwickler von Intel, Yahoo! und Alibaba zu den Stammentwicklern.\\

Die Kommunikation innerhalb der Entwickler- und Anwendergemeinschaft findet wesentlich in den offiziellen Mailinglisten (Abb. \ref{fig:mailinglisten}) und dem Issue-Tracker\cite{issuetracker} der Apache Software Foundation statt.

\begin{figure}[ht!]
	\centering
	\begin{tikzpicture}
	\begin{axis}[
			title={Aktivität auf den Spark-Mailinglisten},
			xlabel={Monat},
			ylabel={Nachrichten pro Tag},
			%xmin=0, xmax=100,
			ymin=0, ymax=100,
			symbolic x coords={2014/11,2014/12,2015/01,2015/02,2015/03},
			ytick={0,20,40,60,80,100},
			legend pos=north west,
			ymajorgrids=true,
			grid style=dashed,
	]
	 
	\addplot[
			color=blue,
			mark=square,
			]
			coordinates {
			(2014/11,16.43)
			(2014/12,13.35)
			(2015/01,12.06)
			(2015/02,15.89)
			(2015/03,14.61)
			};

	\addplot[
			color=red,
			mark=diamond,
			]
			coordinates {
			(2014/11,64.43)
			(2014/12,59.58)
			(2015/01,67.64)
			(2015/02,75.64)
			(2015/03,80.58)
			};
			\legend{dev@spark.apache.org,user@spark.apache.org}

	 
	\end{axis}
	\end{tikzpicture}
	\caption{Aktivität auf den offiziellen Spark Mailinglisten}
	\label{fig:mailinglisten}
\end{figure}
\\

\section{Auswahl verwandter Produkte}
\textcolor{gray}{--- Ergänzende oder konkurrierende Produkte ---}\\
\subsection{Hadoop/YARN}
\subsection{Mesos}
\subsection{Flink}
\subsection{MPI}
\subsection{Samza}
\subsection{Storm}
