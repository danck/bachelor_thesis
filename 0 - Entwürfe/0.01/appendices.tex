\begin{appendices}
\section{Installation der Plattform}
\section{Quellcode/Skripte (Auszüge)}
\subsection{Performance-Messungen}

\begin{lstlisting}[caption={Messung der Festplattenperformance - Beispiel: Schreiben einer 512MB Datei},label={lst:measure_harddrive}]
echo 3 > /proc/sys/vm/drop_caches
dd if=/dev/zero of=test512.out bs=512MB count=1
\end{lstlisting}

\begin{lstlisting}[caption={Messung der Netzwerkperformance},label={lst:measure_network}]
iperf -c <IP-Adresse des Peers> -r -P 4
\end{lstlisting}

\subsection{Monitoring}

\begin{lstlisting}[caption={Monitoring des Clusters (Betriebssystem), Beispiel ModelBuilder},label={lst:monitor_cluster}]
#/bin/bash

### ModelBuilder Wrapper Skript

TIME=`date +"%H-%M"`
WORKERS="pi00 pi01 pi02 pi03"

# Start Monitoring
	
for host in $WORKERS; do
  ssh $host "screen -d -m dstat -cdlsmn --output $1.log"
done
screen -d -m dstat -cdlsm --output $1.log

# Run App
/home/daniel/start_modelbuilder.sh $1-$TIME 2>&1 > \
  ~/metrics/$1_$TIME.log 

# Stop Monitoring
for host in $WORKERS; do
  ssh $host 'screen -X quit'
done
screen -X quit

# Collect results
for host in $WORKERS; do
  scp $host:/home/daniel/$1.log ~/metrics/dstat/$1_$host_$TIME.csv
done
cp ~/$1.log ~/metrics/dstat/$1_dell01_$TIME.csv

# Clean up
for host in $WORKERS; do
  ssh $host "rm /home/daniel/$1.log"
done
\end{lstlisting}

\subsection{Realisierung einer einfachen Continuous Deployment Pipeline}\label{subsec:pipeline}
\textit{post-receive}-Hook von dem Git-Repository\footnote{https://git-scm.com/, abgerufen am 06.06.2015} der ModelBuilder-Komponente
\begin{lstlisting}[caption={Einfache Continuous Deployment Pipeline. Beispiel: ModelBuilder},label={lst:cdp_modelbuilder}]
#/bin/bash

export SPARK_HOME=/opt/spark/

# clean up previous build
rm -rf ~/autobuilds/model_builder
cd ~/autobuilds
git clone ~/git/model_builder
cd model_builder

# run build
sbt package
if [ $? -ne "0" ]; then exit 1; fi

# run test suite
sbt test
if [ $? -ne "0" ]; then exit 1; fi

# deploy to cluster
/opt/spark/bin/spark-submit --class "de.haw.bachelorthesis.dkirchner\
.ModelBuilder" --master spark://192.168.206.131:7077 --driver-memory\
256m --executor-memory 384m \
~/autobuilds/model_builder/ [...] /model-builder_2.10-1.0.jar\
hdfs://192.168.206.131:54310/user/daniel/user_emails_corpus1.txt\
<emailaccount> <passwort>
\end{lstlisting}

\section{Konfigurationen}

\begin{lstlisting}[caption={hdfs-site.xml (Auszug): Beispiel mit Replikationsfaktor 1 und Blockgröße 32MB},label={lst:hdfs_config}]
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.block.size</name>
    <value>33554432</value>
  </property>
  <property>
    <name>dfs.permissions</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.datanode.drop.cache.behind.writes</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
    <value>false</value>
  </property>
</configuration>
\end{lstlisting}

Eine vollständige Liste der HDFS-Optionen und -Standardeinstellungen kann unter [\footnote{https://hadoop.apache.org/docs/r2.7.0/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml, abgerufen am 03.06.2015}] eingesehen werden.

\begin{lstlisting}[caption={spark-defaults.conf (Auszug)},label={lst:hdfs_config}]
spark.master                     spark://dell01:7077
spark.eventLog.enabled           true
spark.eventLog.dir               file:///home/spark/metrics/secondary
spark.shuffle.memoryFraction     0.3
\end{lstlisting}

\section{Sonstiges}
\subsection{Einschätzung des theoretischen Spitzendurchsatzes von Mittelklasse-Servern}
\label{subsec:commodity_servers}
Um zu einer groben Einschätzung des möglichen Datendurchsatzes verschiedener Schnittstellen bei "`Commodity Servern"' zu gelangen, wurden drei Systeme von großen Herstellern ausgewählt.\\
In der Grundkonfiguration kosten diese Systeme (zum Zeitpunkt dieser Arbeit) um die € 2000,- und lassen damit auf die Größenordnungen bei dem Datendurchsatz bestimmter Schnittstellen bei preisgünstigen Mehrzweck-Rechenknoten schließen.

\begin{table}[ht]
	\centering % used for centering table
	\begin{tabular}{c c c c} % centered columns (4 columns)
		\hline\hline %inserts double horizontal lines
		Modell & Netzwerkschnittstelle & Festspeicher & Arbeitsspeicher\\ [0.5ex] % inserts table
		%heading
		\hline % inserts single horizontal line
		Dell PowerEdge R530 & 1Gb/s Ethernet & PCIe 3.0 & DDR4\\ 
		HP Proliant DL160 Gen8 & 1Gb/s Ethernet & PCIe 3.0 & DDR3\\ 
		System x3650 M5 & 1Gb/s Ethernet & PCIe 3.0 & DDR4\\ % inserting body of the table
		\hline %inserts single line
	\end{tabular}
	\caption{Theoretische Spitzenleistungen bei Mehrzweck-Servern der 2000 Euro Klasse} % title of Table
	\label{table:vglinterfaces} % is used to refer this table in the text
\end{table}

Mit \cite{PCI14} und \cite{Fuj11} lassen sich grobe obere Abschätzungen errechnen, die in Tabelle~\ref{table:vgldurchsatz} angegeben sind.

\end{appendices}