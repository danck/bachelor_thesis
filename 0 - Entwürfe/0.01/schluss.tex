\chapter{Schlussbetrachtung}
\section{Diskussion der Ergebnisse}
Es wurde eine Anwendung entworfen und implementiert, die einen Echtzeitdatenstrom nach vorgegebenen Kriterien analysiert und dabei dynamisch auf geänderte Vorgaben reagieren kann.\\
Diese Anwendung wurde anschließend als Testfall für den Betrieb einer Apache Spark/Hadoop-Umgebung auf einem Low-End-Hardware-Cluster aus Raspberry Pis genutzt und das Laufzeitverhalten untersucht.\\

Dieser Versuch war erfolgreich. Es ist möglich einen Spark/Hadoop-Cluster auf der beschriebenen Hardware zu betreiben und die genannte Anwendung stabil zu betreiben.\\

Dabei hat sich die Hardware sogar als leistungsfähiger als nötig erwiesen. Zwar profitiert insbesondere die Batch-Komponente deutlich von dem Hinzufügen weiterer Knoten, die Streaming-Komponente ist jedoch mit einem einzelnen Knoten bereits problemlos zu betreiben und erfährt durch verteilte Ausführung keine weitere Verbesserung der Performance.\\

Die geringe Last des kostenlosen Twitterdatenstroms verursacht für die weitere Bewertung der Ergebnisse zwei Probleme:
\begin{enumerate}
	\item Da selbst ein einzelner Knoten für die Analyse des Datenstroms mehr als ausreichend ist, lassen sich aus dem Experiment keine Aussagen über das Skalierungsverhalten der entsprechenden Komponente treffen.
	\item Bei der Exploration mehrerer zehntausend Tweets wurde kein einziger mit einem plausiblen Bezug zu den in der Spark-Mailingliste diskutierten Themen gefunden. Eine empirische Bewertung der funktionalen Qualitäten der Implementation ist damit nicht ohne Weiteres möglich.
\end{enumerate}

\section{Ausblick und offene Punkte}
Der Betrieb eines Spark/Hadoop-Clusters ist komplex. In dieser Arbeit wurde die Anwendungsentwicklung mit Spark und die Machbarkeit des Betriebs auf Low-End-Hardware behandelt. Für einen produktiven Betrieb der hier vorgestellten Architektur gibt es eine Reihe von Maßnahmen, die im Rahmen der betrachteten Fragestellungen ausgeblendet wurden:\\

\begin{enumerate}
	\item \textbf{Message Queues:} Für die robuste Verbindung zur asynchronen Kommunikation zwischen Batch- und Realtime-Komponente käme eine Erweiterung mt Messagequeues oder auch (NoSQL-)Datenbanken in Frage.
	\item \textbf{Umfangreichere Datenquellen:} Um die Skalierbarkeit der Streaming-Komponente unabhängig vom dem hier behandelten Anwendungsfall zu betrachten, könnte man einen eigenen speziellen Receiver implementieren und diesen mit einer kontrollierbaren Datenquelle verbinden. \textit{Kontrollierbar} heißt hier, dass die erzeugte Last flexibel erhöht werden kann, um die Kapazität des empfangenden Knotens zu übertreffen und eine verteilte Verarbeitung zu erzwingen.
	\item \textbf{Clustermanagement:} Die Konfiguration der Knoten und der verteilten Komponenten wurde für diesen Versuch überwiegend manuell durchgeführt. Um auch eine höhere Anzahl von Knoten verwalten zu können wären Werkzeuge zur Automatisierung von Konfiguration (z.B. Chef\footnote{https://www.chef.io/chef/}, Puppet\footnote{https://puppetlabs.com/}) oder Provisionierung (z.B. Docker\footnote{https://www.docker.com}, Rocket\footnote{https://github.com/coreos/rkt}, Kubernetes\footnote{http://kubernetes.io/}) notwendig.\\
	Für ein professionelles Monitoring könnte man den Cluster mit Tools zur dauerhaften Überwachung ausstatten (z.B. Nagios/Icinga\footnote{https://www.icinga.org/}, Ganglia\footnote{http://ganglia.sourceforge.net/}).
\end{enumerate}

Neben dem Betrieb der Anwendung, gibt es auch funktionale Aspekte die für eine produktive Anwendung erweitert werden könnten:

\begin{enumerate}
	\item \textbf{Textkorpus:} Als Textkorpus für das TF-IDF-Verfahren wurde für diesen \textit{Proof of Concept} der vervielfachte Inhalt von Nachrichten aus der Spark-User-Mailingliste verwendet (etwa 13000 Emails). Eine schärfere Abgrenzung relevanter Begriffe lässt sich wahrscheinlich durch einen unabhängigen Korpus erreichen (beispielsweise Wikipedia\footnote{http://www.wikipedia.org/} oder der klassische Reuters-Nachrichtenkorpus\footnote{https://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html, abgerufen am 01.06.2015}).
	\item \textbf{Ähnlichkeitsmaß:} Das Scoring könnte darüber hinaus durch leistungsfähigere Verfahren verbessert werden - etwa durch Ähnlichkeitsmaße (\cite{Huang:2008}), die auch Synonyme erkennen.
	\item \textbf{Grafische Benutzeroberfläche:} Damit die gefilterten Nachrichten ihren Weg zum Benutzer finden, gibt es eine Vielzahl an Möglichkeiten. Naheliegend wäre ein Webinterface (z.B. über den MEAN-Stack\footnote{http://mean.io/#!/} oder das Play-Framework\footnote{https://www.playframework.com/} für Scala/Java).
\end{enumerate}