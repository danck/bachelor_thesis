\documentclass[draft=false
              ,paper=a4
              ,twoside=false
              ,fontsize=11pt
              ,headsepline
              ,BCOR10mm
              ,DIV11
              ]{scrbook}
\usepackage[ngerman,english]{babel}
%% see http://www.tex.ac.uk/cgi-bin/texfaq2html?label=uselmfonts
\usepackage[T1]{fontenc}
%\usepackage[utf8]{inputenc}
\usepackage[latin1]{inputenc}
\usepackage{libertine}
\usepackage{pifont}
\usepackage{microtype}
\usepackage{textcomp}
\usepackage[german,refpage]{nomencl}
\usepackage{setspace}
\usepackage{makeidx}
\usepackage{listings}
\usepackage{natbib}
\usepackage[ngerman,colorlinks=true]{hyperref}
\usepackage{soul}
\usepackage{hawstyle}
\usepackage{lipsum} %% for sample text

%% define some colors
\colorlet{BackgroundColor}{gray!20}
\colorlet{KeywordColor}{blue}
\colorlet{CommentColor}{black!60}
%% for tables
\colorlet{HeadColor}{gray!60}
\colorlet{Color1}{blue!10}
\colorlet{Color2}{white}

%% configure colors
\HAWifprinter{
  \colorlet{BackgroundColor}{gray!20}
  \colorlet{KeywordColor}{black}
  \colorlet{CommentColor}{gray}
  % for tables
  \colorlet{HeadColor}{gray!60}
  \colorlet{Color1}{gray!40}
  \colorlet{Color2}{white}
}{}
\lstset{%
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=5pt,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{KeywordColor}\bfseries,
  identifierstyle=\color{black},
  commentstyle=\color{CommentColor},
  backgroundcolor=\color{BackgroundColor},
  captionpos=b,
  fontadjust=true
}
\lstset{escapeinside={(*@}{@*)}, % used to enter latex code inside listings
        morekeywords={uint32_t, int32_t}
}
\ifpdfoutput{
  \hypersetup{bookmarksopen=false,bookmarksnumbered,linktocpage}
}{}

%% more fancy C++
\DeclareRobustCommand{\cxx}{C\raisebox{0.25ex}{{\scriptsize +\kern-0.25ex +}}}

\clubpenalty=10000
\widowpenalty=10000
\displaywidowpenalty=10000

% unknown hyphenations
\hyphenation{
}

%% recalculate text area
\typearea[current]{last}

\makeindex
\makenomenclature

\begin{document}
\selectlanguage{ngerman}

%%%%%
%% customize (see readme.pdf for supported values)
\HAWThesisProperties{Author={Daniel Kirchner}
                    ,Title={Skalierbare Datenanalyse mit Apache Spark}
										,SubTitle={Beispielimplementation eines Influenza-Frühwarnsystems}
                    ,EnglishTitle={Scalable Data Analysis with Apache Spark}
                    ,ThesisType={Bachelorarbeit}
                    ,ExaminationType={Bachelorprüfung}
                    ,DegreeProgramme={Bachelor of Science Angewandte Informatik}
                    ,ThesisExperts={Prof. Dr. Kahlbrandt \and Prof. Dr. Zweitprüfer}
                    ,ReleaseDate={1. Januar 2345}
                  }

%% title
\frontmatter

%% output title page
\maketitle

\onehalfspacing

%% add abstract pages
%% note: this is one command on multiple lines
\HAWAbstractPage
%% German abstract
{Schlüsselwort 1, Schlüsselwort 2}%
{Dieses Dokument \ldots}
%% English abstract
{keyword 1, keyword 2}%
{This document \ldots}

\newpage
\singlespacing

\tableofcontents

\newpage
%% enable if these lists should be shown on their own page
%%\listoftables
%%\listoffigures
\lstlistoflistings

%% main
\mainmatter
\onehalfspacing
%% write to the log/stdout
\typeout{===== File: chapter 1}
%% include chapter file (chapter1.tex)
%%\include{chapter1}

%%%%
%% add some text to generate a sample document
\chapter{Einf\"uhrung}

\section{Motivation}
Der Bedarf auf großen Datenmengen zu operieren ist nicht neu. Spätestens seit in den sp\"aten Neunzigerjahren Suchmaschinenanbieter mit Mengen von Daten und Anfragen konfrontiert wurden, die nicht mehr wirtschaftlich durch einzelne Rechner zu bew\"altigen waren, wurden neue Verfahren benötigt. 
Algorithmen wurden auf Verteilbarkeit und Fehlertoleranz optimiert.
\break

Die Analyse großer Datenmengen ist auch für Unternehmen und Einrichtungen interessant geworden, deren Kerngesch\"aft nicht die Daten selbst sind. Regierungen, Wissenschaft, Industrieunternehmen, Militär, B\"orsenh\"andel und viele andere treffen Entscheidungen auf Grundlage von Daten die die Kapazitäten einzelner Maschinen weit überschreiten.
\break

Häufige Ver\"anderung und Unvorhersehbarkeit der Anforderungen sind allt\"aglich. Daten denen man zunächst keine Bedeutung beimisst, können sich später als sehr kritisch erweisen und in anderem Zusammenhang eine wichtige Rolle spielen. 
Ein Verfahren hat sich in diesem Rahmen als besonders wirksam herausgestellt: Daten werden schwach strukturiert gespeichert und erst zum Zeitpunkt einer Operation in die jeweils gewünschte Struktur gebracht.
\break

Solche Abfragen werden bei aktuellen Systemen oft in Form kleiner Programme gestellt, die auf den Knoten eines Clusters nach einem vorgegebenem Paradigma ausgeführt werden.
Hier kommt das Cluster-Computing-Framework Apache Spark ins Spiel, das mehrere solcher Paradigmen vereint und als universelle Lösung für viele aktuelle Aufgaben der "`Big Data"' Analyse antritt.

\section{Kontextabgrenzung}

\section{Relevante Produkte und Meilensteine}

\subsection{\"Uberblick}
\subsection{Big Table}
\subsection{Map/Reduce}
\subsection{Hadoop}

\chapter{Vorstellung von Apache Spark}

\section{\"Ubersicht}
\subsection{Architekturübersicht}
\subsection{Standardbibliotheken}
\subsubsection{Spark SQL}
\subsubsection{MLlib}
\subsubsection{Streaming}
\subsubsection{GraphX}

\section{Wesentliche Konzepte}
\subsection{Abgrenzung zu Hadoop}
\subsection{Resilient Distributed Datasets}


\chapter{Vorstellung des Beispiels}
\section{Aufgabenbeschreibung}
\section{L\"osungsidee}
\subsection{1. Schritt: \"Ahnlichkeitsma{\ss} für W\"orter erzeugen}
\subsection{2. Schritt: Echtzeitbewertung von Textnachrichten aus einem Datenstrom}


\chapter{Implementation und Bewertung}
\section{Betriebsumgebung}
Die Wahl einer Betriebsumgebung für Cluster-Computing-Frameworks stellt besondere Anforderungen. Obwohl Installationen einer lauffähigen Instanz von Apache Spark auch für einzelne Maschinen möglich ist, werden solche Setups einer Demonstration und Untersuchung von verteiltem Rechnen offenbar nicht gerecht.

Auf der anderen Seite bringen verteilte und auf physikalischen Rechnern laufende Installationen zusätzliche Probleme mit. Ausfälle von Hardwarekomponenten auf Rechenknoten und Netzwerken, Stromkosten für Betrieb und Kühlung, sowie Beschaffungs- oder Mietkosten für Räumlichkeiten und Komponenten sind nur die offensichtlichsten.
\break

Im Rahmen dieser Arbeit sollen Konzepte demonstriert und bewertet werden. Ein produktionstaugliches System ist hingegen nicht gefordert. Es ergeben sich die folgenden Punkte. 

Anforderungen:
\begin{itemize}
	\item echte Verteilung der Komponenten
	\item volle Kontrolle über die lokalen Abläufe
\end{itemize}

Keine Anforderungen:
\begin{itemize}
	\item hohe Performance
	\item authentische Bedingungen eines Rechenzentrums
\end{itemize}

Gemäß dieser Anforderungen kommt ein KVM-virtualisierter Host zum Einsatz mit folgender Ausstattung:
\begin{itemize}
	\item Intel® Xeon® E5-2670V2
	\item 4 dedizierte Kerne
	\item 16GB DDR3 RAM
	\item Betriebssystem Fedora 20 GNU/Linux
\end{itemize}

Die Verteilung erfolgt auf virtuellen Maschinen innerhalb dieses Hosts. Diese Maschinen und deren Netzwerkverbindungen werden durch die Cloud Computing Software OpenStack (Release Juno) erzeugt und verwaltet.

\subsection{Verteilungsdiagramm}


\section{Architekturübersicht}
\section{Architekturdetails}
\subsection{Modell f\"ur \"Ahnlichkeit von W\"ortern mit MLlib erzeugen}
\subsection{Einlesen von Nachrichten aus dem Twitter Livestream}
\subsection{Verarbeiten und Bewerten der Nachrichten}
\section{Bewertung der Verfahren}

\chapter{Schlussbetrachtung}
\section{Kritische W\"urdigung der Ergebnisse}
\section{Ausblick und offene Punkte}

%%\lipsum

See also \cite{sample_bib}.
%%%%

%% appendix if used
%%\appendix
%%\typeout{===== File: appendix}
%%\include{appendix}

% bibliography and other stuff
\backmatter

\typeout{===== Section: literature}
%% read the documentation for customizing the style
\bibliographystyle{dinat}
\bibliography{sample}

\typeout{===== Section: nomenclature}
%% uncomment if a TOC entry is needed
%%\addcontentsline{toc}{chapter}{Glossar}
\renewcommand{\nomname}{Glossar}
\clearpage
\markboth{\nomname}{\nomname} %% see nomencl doc, page 9, section 4.1
\printnomenclature

%% index
\typeout{===== Section: index}
\printindex

\HAWasurency

\end{document}
