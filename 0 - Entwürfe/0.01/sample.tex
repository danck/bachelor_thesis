\documentclass[draft=false
              ,paper=a4
              ,twoside=false
              ,fontsize=11pt
              ,headsepline
              ,BCOR10mm
              ,DIV11
              ]{scrbook}
\usepackage[ngerman,english]{babel}
%% see http://www.tex.ac.uk/cgi-bin/texfaq2html?label=uselmfonts
\usepackage[T1]{fontenc}
%\usepackage[utf8]{inputenc}
\usepackage[latin1]{inputenc}
\usepackage{libertine}
\usepackage{pifont}
\usepackage{microtype}
\usepackage{textcomp}
\usepackage[german,refpage]{nomencl}
\usepackage{setspace}
\usepackage{makeidx}
\usepackage{listings}
\usepackage{natbib}
\usepackage[ngerman,colorlinks=true]{hyperref}
\usepackage{soul}
\usepackage{hawstyle}
\usepackage{lipsum} %% for sample text

%% define some colors
\colorlet{BackgroundColor}{gray!20}
\colorlet{KeywordColor}{blue}
\colorlet{CommentColor}{black!60}
%% for tables
\colorlet{HeadColor}{gray!60}
\colorlet{Color1}{blue!10}
\colorlet{Color2}{white}

%% configure colors
\HAWifprinter{
  \colorlet{BackgroundColor}{gray!20}
  \colorlet{KeywordColor}{black}
  \colorlet{CommentColor}{gray}
  % for tables
  \colorlet{HeadColor}{gray!60}
  \colorlet{Color1}{gray!40}
  \colorlet{Color2}{white}
}{}
\lstset{%
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=5pt,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{KeywordColor}\bfseries,
  identifierstyle=\color{black},
  commentstyle=\color{CommentColor},
  backgroundcolor=\color{BackgroundColor},
  captionpos=b,
  fontadjust=true
}
\lstset{escapeinside={(*@}{@*)}, % used to enter latex code inside listings
        morekeywords={uint32_t, int32_t}
}
\ifpdfoutput{
  \hypersetup{bookmarksopen=false,bookmarksnumbered,linktocpage}
}{}

%% more fancy C++
\DeclareRobustCommand{\cxx}{C\raisebox{0.25ex}{{\scriptsize +\kern-0.25ex +}}}

\clubpenalty=10000
\widowpenalty=10000
\displaywidowpenalty=10000

% unknown hyphenations
\hyphenation{
}

%% recalculate text area
\typearea[current]{last}

\makeindex
\makenomenclature

\begin{document}
\selectlanguage{ngerman}

%%%%%
%% customize (see readme.pdf for supported values)
\HAWThesisProperties{Author={Daniel Kirchner}
                    ,Title={Skalierbare Datenanalyse mit Apache Spark}
										,SubTitle={Beispielimplementation eines Influenza-Frühwarnsystems}
                    ,EnglishTitle={Scalable Data Analysis with Apache Spark}
                    ,ThesisType={Bachelorarbeit}
                    ,ExaminationType={Bachelorprüfung}
                    ,DegreeProgramme={Bachelor of Science Angewandte Informatik}
                    ,ThesisExperts={Prof. Dr. Kahlbrandt \and Prof. Dr. Zweitprüfer}
                    ,ReleaseDate={1. Januar 2345}
                  }

%% title
\frontmatter

%% output title page
\maketitle

\onehalfspacing

%% add abstract pages
%% note: this is one command on multiple lines
\HAWAbstractPage
%% German abstract
{Schlüsselwort 1, Schlüsselwort 2}%
{Dieses Dokument \ldots}
%% English abstract
{keyword 1, keyword 2}%
{This document \ldots}

\newpage
\singlespacing

\tableofcontents

\newpage
%% enable if these lists should be shown on their own page
%%\listoftables
%%\listoffigures
\lstlistoflistings

%% main
\mainmatter
\onehalfspacing
%% write to the log/stdout
\typeout{===== File: chapter 1}
%% include chapter file (chapter1.tex)
%%\include{chapter1}

%%%%
%% add some text to generate a sample document
\chapter{Einf\"uhrung}

\section{Motivation}
Der Bedarf auf großen Datenmengen zu operieren ist nicht neu. Spätestens seit in den sp\"aten Neunzigerjahren Suchmaschinenanbieter mit Mengen von Daten und Anfragen konfrontiert wurden, die nicht mehr wirtschaftlich durch einzelne Rechner oder kleine Rechnerverbünde zu bew\"altigen waren, wurden neue Verfahren benötigt. 
Algorithmen wurden auf Verteilbarkeit und Fehlertoleranz optimiert.
\break

Die Menge verfügbarer Daten wuchs und wurde auch für Unternehmen und Einrichtungen interessant, deren Kerngesch\"aft nicht die Daten selbst sind. Regierungen, Wissenschaft, Industrieunternehmen, Militär, B\"orsenh\"andel und viele andere treffen Entscheidungen auf Grundlage von Daten die die Kapazitäten einzelner Maschinen weit überschreiten.
\break

Häufige Ver\"anderung und Unvorhersehbarkeit der Anforderungen sind allt\"aglich. Daten denen man zunächst keine Bedeutung beimisst, können sich später als sehr kritisch erweisen und in anderem Zusammenhang eine wichtige Rolle spielen. 
Ein Verfahren hat sich in diesem Rahmen als besonders wirksam herausgestellt: Daten werden schwach strukturiert gespeichert und erst zum Zeitpunkt einer Abfrage (oder beliebigen Operation) in eine jeweils sinnvolle Struktur gebracht.
\break

Solche Abfragen werden bei aktuellen Systemen oft in Form kleiner Programme gestellt, die auf den Knoten eines Clusters verteilt und nach einem vorgegebenem Paradigma ausgeführt werden.
Hier kommt das Cluster-Computing-Framework Apache Spark ins Spiel, das mehrere solcher Paradigmen vereint und als bisher vielseitigste Lösung für viele aktuelle Aufgaben der "`Big Data"' Analyse antritt.

\section{Kontextabgrenzung}

\section{Relevante Produkte und Meilensteine}

\subsection{\"Uberblick}
\subsection{Big Table}
\subsection{Map/Reduce}
\subsection{Hadoop}

\chapter{Vorstellung von Apache Spark}

\section{\"Ubersicht}
\subsection{Architekturübersicht}
\subsection{Standardbibliotheken}
\subsubsection{Spark SQL}
\subsubsection{MLlib}
\subsubsection{Streaming}
\subsubsection{GraphX}

\section{Wesentliche Konzepte}
\subsection{Abgrenzung zu Hadoop}
\subsection{Resilient Distributed Datasets}


\chapter{Vorstellung des Beispiels}
\section{Aufgabenbeschreibung}
\section{L\"osungsidee}
\subsection{1. Schritt: \"Ahnlichkeitsma{\ss} für W\"orter erzeugen}
\subsection{2. Schritt: Echtzeitbewertung von Textnachrichten aus einem Datenstrom}


\chapter{Implementation und Bewertung}
\section{Betriebsumgebung}
Die Wahl einer Betriebsumgebung für Cluster-Computing-Frameworks stellt besondere Anforderungen. Obwohl Installationen einer lauffähigen Instanz von Apache Spark auch für einzelne Maschinen möglich ist, werden solche Setups einer Demonstration und Untersuchung von verteiltem Rechnen offensichtlich nicht gerecht.

Auf der anderen Seite bringen verteilte und auf physikalischen Rechnern laufende Installationen zusätzliche Probleme mit. Ausfälle von Hardwarekomponenten auf Rechenknoten und Netzwerken, Stromkosten für Betrieb und Kühlung, sowie Beschaffungs- oder Mietkosten für Räumlichkeiten und Komponenten sind nur die offensichtlichsten.
\break

Im Rahmen dieser Arbeit sollen Konzepte demonstriert und bewertet werden. Ein produktionstaugliches System ist  nicht gefordert. Es ergeben sich die folgenden Vorgaben. 
\break

Anforderungen:
\begin{itemize}
	\item echte Verteilung der Komponenten
	\item volle Kontrolle über die lokalen Abläufe
\end{itemize}

Keine Anforderungen:
\begin{itemize}
	\item hohe Performance
	\item authentische Bedingungen eines Rechenzentrums
\end{itemize}

Gemäß dieser Anforderungen kommt ein KVM-virtualisierter Host zum Einsatz der als Plattform für eine Cloud Computing Software dient, um ein kleines Cluster von virtuellen Maschinen zu Verfügung zu stellen.
\break

Technische Daten des Hosts
\begin{itemize}
	\item CPU Intel® Xeon® E5-2670V2
	\item 4 dedizierte Kerne
	\item 16GB DDR3 RAM
	\item Betriebssystem Fedora 20 GNU/Linux
	\item Cloud Software OpenStack (Release Juno)
\end{itemize}

Das Cluster selbst besteht aus 3 gleichartigen virtuellen Maschinen innerhalb eines OpenStack Tenants und dem Host selbst. Um die untersuchte Installation in andere Betriebsumgebungen zu bringen oder schnell wiederherstellen zu können, sind die Installationen der Apache Spark Komponenten jeweils in Docker Containern (basierend auf LXC) durchgeführt.
Dadurch daraus ergeben sich drei Laufzeitumgebungen für den Entwicklungs- und Untersuchungsprozess:
\break

\begin{itemize}
	\item Lokale Single-Node-Installation: Exploration, Entwicklung, Debugging
	\item {[}Docker{]} Virtuelles Cluster auf einzelner physiklischen Maschine: Entwicklung und Debugging im verteilten Betrieb
	\item {[}Docker{]} Virtuelles Cluster auf verteilten physikalischen Maschinen: Performance-Messungen, Analyse von Skalierungsverhalten
\end{itemize}


Technische Daten der virtuellen Cluster-Knoten
\begin{itemize}
	\item 2 virtuelle CPUs
	\item 2GB RAM
	\item Betriebssystem CoreOS
	\item Netzwerkvirtualisierung mit der OpenStack-Komponente Neutron
\end{itemize}

\subsection{Verteilungsdiagramm}


\section{Architekturübersicht}
\section{Architekturdetails}
\subsection{Modell f\"ur \"Ahnlichkeit von W\"ortern mit MLlib erzeugen}
\subsection{Einlesen von Nachrichten aus dem Twitter Livestream}
\subsection{Verarbeiten und Bewerten der Nachrichten}
\section{Bewertung der Verfahren}

\chapter{Schlussbetrachtung}
\section{Kritische W\"urdigung der Ergebnisse}
\section{Ausblick und offene Punkte}

%%\lipsum

See also \cite{sample_bib}.
%%%%

%% appendix if used
%%\appendix
%%\typeout{===== File: appendix}
%%\include{appendix}

% bibliography and other stuff
\backmatter

\typeout{===== Section: literature}
%% read the documentation for customizing the style
\bibliographystyle{dinat}
\bibliography{sample}

\typeout{===== Section: nomenclature}
%% uncomment if a TOC entry is needed
%%\addcontentsline{toc}{chapter}{Glossar}
\renewcommand{\nomname}{Glossar}
\clearpage
\markboth{\nomname}{\nomname} %% see nomencl doc, page 9, section 4.1
\printnomenclature

%% index
\typeout{===== Section: index}
\printindex

\HAWasurency

\end{document}
