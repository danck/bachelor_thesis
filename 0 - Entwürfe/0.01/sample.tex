\documentclass[draft=false
              ,paper=a4
              ,twoside=false
              ,fontsize=11pt
              ,headsepline
              ,BCOR10mm
              ,DIV11
              ]{scrbook}
\usepackage[ngerman,english]{babel}
%% see http://www.tex.ac.uk/cgi-bin/texfaq2html?label=uselmfonts
\usepackage[T1]{fontenc}
%\usepackage[utf8]{inputenc}
\usepackage[latin1]{inputenc}
\usepackage{libertine}
\usepackage{pifont}
\usepackage{microtype}
\usepackage{textcomp}
\usepackage[german,refpage]{nomencl}
\usepackage{setspace}
\usepackage{makeidx}
\usepackage{listings}
\usepackage{natbib}
\usepackage[ngerman,colorlinks=true]{hyperref}
\usepackage{soul}
\usepackage{hawstyle}
\usepackage{lipsum} %% for sample text

%% define some colors
\colorlet{BackgroundColor}{gray!20}
\colorlet{KeywordColor}{blue}
\colorlet{CommentColor}{black!60}
%% for tables
\colorlet{HeadColor}{gray!60}
\colorlet{Color1}{blue!10}
\colorlet{Color2}{white}

%% configure colors
\HAWifprinter{
  \colorlet{BackgroundColor}{gray!20}
  \colorlet{KeywordColor}{black}
  \colorlet{CommentColor}{gray}
  % for tables
  \colorlet{HeadColor}{gray!60}
  \colorlet{Color1}{gray!40}
  \colorlet{Color2}{white}
}{}
\lstset{%
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=5pt,
  basicstyle=\ttfamily\small,
  keywordstyle=\color{KeywordColor}\bfseries,
  identifierstyle=\color{black},
  commentstyle=\color{CommentColor},
  backgroundcolor=\color{BackgroundColor},
  captionpos=b,
  fontadjust=true
}
\lstset{escapeinside={(*@}{@*)}, % used to enter latex code inside listings
        morekeywords={uint32_t, int32_t}
}
\ifpdfoutput{
  \hypersetup{bookmarksopen=false,bookmarksnumbered,linktocpage}
}{}

%% more fancy C++
\DeclareRobustCommand{\cxx}{C\raisebox{0.25ex}{{\scriptsize +\kern-0.25ex +}}}

\clubpenalty=10000
\widowpenalty=10000
\displaywidowpenalty=10000

% unknown hyphenations
\hyphenation{
}

%% recalculate text area
\typearea[current]{last}

\makeindex
\makenomenclature

\begin{document}
\selectlanguage{ngerman}

%%%%%
%% customize (see readme.pdf for supported values)
\HAWThesisProperties{Author={Daniel Kirchner}
                    ,Title={Skalierbare Datenanalyse mit Apache Spark}
										,SubTitle={Beispielimplementation eines Influenza-Frühwarnsystems}
                    ,EnglishTitle={Scalable Data Analysis with Apache Spark}
                    ,ThesisType={Bachelorarbeit}
                    ,ExaminationType={Bachelorprüfung}
                    ,DegreeProgramme={Bachelor of Science Angewandte Informatik}
                    ,ThesisExperts={Prof. Dr. Kahlbrandt \and Prof. Dr. Zweitprüfer}
                    ,ReleaseDate={1. Januar 2345}
                  }

%% title
\frontmatter

%% output title page
\maketitle

\onehalfspacing

%% add abstract pages
%% note: this is one command on multiple lines
\HAWAbstractPage
%% German abstract
{Schlüsselwort 1, Schlüsselwort 2}%
{Dieses Dokument \ldots}
%% English abstract
{keyword 1, keyword 2}%
{This document \ldots}

\newpage
\singlespacing

\tableofcontents

\newpage
%% enable if these lists should be shown on their own page
%%\listoftables
%%\listoffigures
\lstlistoflistings

%% main
\mainmatter
\onehalfspacing
%% write to the log/stdout
\typeout{===== File: chapter 1}
%% include chapter file (chapter1.tex)
%%\include{chapter1}

%%%%
%% add some text to generate a sample document
\chapter{Einf\"uhrung}

\section{Motivation}
Der Bedarf auf großen Datenmengen zu operieren ist nicht neu. Spätestens seit in den sp\"aten Neunzigerjahren Suchmaschinenanbieter mit Mengen von Daten und Anfragen konfrontiert wurden, die eine nicht mehr wirtschaftlich durch einzelne Rechner zu bew\"altigen waren, wurden neue Verfahren benötigt. 
Algorithmen wurden nun auf die Eigenschaft optimiert möglichst effizient und fehlertolerant auf verschiedene Maschinen verteilbar zu sein.
\break

Inzwischen ist die Analyse großer Datenmengen auch für Unternehmen und Einrichtungen interessant geworden, deren Kerngesch\"aft nicht die Daten selbst sind. Regierungen, Wissenschaftler, Industrieunternehmen, Militärs, Handelssoftware und viele andere treffen Entscheidungen auf Grundlage von Daten die die Kapazitäten einzelner Systeme weit übeschreiten.
\break

St\"andige Ver\"anderung und Unvorhersehbarkeit der Anforderungen sind allt\"agliche Praxis. Daten denen man in dem Moment keine Bedeutung beimisst, können sich in Zukunft als sehr kritisch erweisen und in einem anderen Kontext eine wichtige Rolle spielen. 
Dabei hat sich ein Paradigma als besonders wirksam herausgestellt: Daten werden erst durch die Abfrage in eine höhere Struktur gebracht, während bei der Speicherung nur ein Minimum an Struktur eingefordert wird.
\break

Ein weiteres Problem ist die Vielfalt der möglichen Abfragen. Für bestimmte Aufgaben gen\"ugen Anfragen wie an eine klassische Datenbank. F\"ur andere Probleme sind möglicherweise komplexere Graph-Analysen, das Anlernen von Maschinenlernalgorithmen oder eine Quasi-Echtzeit-Auswertung von Datenströmen gefordert.
An dieser Stelle kommt Apache Spark ins Spiel, dass einen Versuch macht alle bisher genannten Probleme zu lösen.


\section{Kontextabgrenzung}

\section{Relevante Produkte und Meilensteine}

\subsection{\"Uberblick}
\subsection{Big Table}
\subsection{Map/Reduce}
\subsection{Hadoop}

\chapter{Vorstellung von Apache Spark}

\section{\"Ubersicht}
\subsection{Architekturübersicht}
\subsection{Standardbibliotheken}
\subsubsection{Spark SQL}
\subsubsection{MLlib}
\subsubsection{Streaming}
\subsubsection{GraphX}

\section{Wesentliche Konzepte}
\subsection{Abgrenzung zu Hadoop}
\subsection{Resilient Distributed Datasets}


\chapter{Vorstellung des Beispiels}
\section{Aufgabenbeschreibung}
\section{L\"osungsidee}
\subsection{1. Schritt: \"Ahnlichkeitsma{\ss} für W\"orter erzeugen}
\subsection{2. Schritt: Echtzeitbewertung von Textnachrichten aus einem Datenstrom}


\chapter{Implementation und Bewertung}
\section{Technischer Rahmen}
\subsection{OpenStack}
\section{Architekturübersicht}
\section{Architekturdetails}
\subsection{Modell f\"ur \"Ahnlichkeit von W\"ortern mit MLlib erzeugen}
\subsection{Einlesen von Nachrichten aus dem Twitter Livestream}
\subsection{Verarbeiten und Bewerten der Nachrichten}
\section{Bewertung der Verfahren}

\chapter{Schlussbetrachtung}
\section{Kritische W\"urdigung der Ergebnisse}
\section{Ausblick und offene Punkte}

%%\lipsum

See also \cite{sample_bib}.
%%%%

%% appendix if used
%%\appendix
%%\typeout{===== File: appendix}
%%\include{appendix}

% bibliography and other stuff
\backmatter

\typeout{===== Section: literature}
%% read the documentation for customizing the style
\bibliographystyle{dinat}
\bibliography{sample}

\typeout{===== Section: nomenclature}
%% uncomment if a TOC entry is needed
%%\addcontentsline{toc}{chapter}{Glossar}
\renewcommand{\nomname}{Glossar}
\clearpage
\markboth{\nomname}{\nomname} %% see nomencl doc, page 9, section 4.1
\printnomenclature

%% index
\typeout{===== Section: index}
\printindex

\HAWasurency

\end{document}
