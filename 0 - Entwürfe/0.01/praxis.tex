\chapter{Entwicklung und Betrieb einer Beispielanwendung}

In diesem Kapitel wird die Entwicklung einer Anwendung für Spark und der Betrieb auf einem Cluster mit leistungsschwacher Hardware demonstriert und untersucht.

\section{Vorstellung der Beispielanwendung}

Als Demonstration der Anwendungsentwicklung und des Anwendungsbetriebes mit Spark soll ein Backend zur Nachrichtenanalyse implementiert werden.\\
Nachrichten sind in diesem Fall Tweets, die über die kostenlose Streaming-\gls{API}\footnote{https://dev.twitter.com/streaming/sitestreams, abgerufen am 06.06.2015} von Twitter\footnote{https://twitter.com, abgerufen am 06.06.2015} übertragen  und anschließend bewertet werden sollen.\\
Die Bewertung soll anhand inhaltlicher Ähnlichkeit mit aktuellen Diskussionen innerhalb der Mailingliste\footnote{user@spark.apache.org, abgerufen am 15.06.2015} von Sparkbenutzern erfolgen.\\

In Abbildung~\ref{figure:demo_app_usecase} wird der zugehörige Anwendungsfall dargestellt. Für die Beispielanwendung wird nur das Backend implementiert. Die grafische Benutzeroberfläche wird jedoch stellenweise erwähnt, um einen klaren Kontext zu setzen.\\

\begin{figure}[ht!]
	\centering
  \includegraphics[width=0.9\textwidth]{demo_app_usecase.pdf}
	\caption{Anwendungsfalldiagramm der Demo-Applikation}
	\label{figure:demo_app_usecase}
\end{figure}

Die Analyse der Tweets soll in Quasi-Echtzeit erfolgen und direkt anschließend an eine Datensenke weitergereicht werden (dort wäre beispielsweise eine Messagequeue oder Datenbank zur Weiterleitung an eine grafische Benutzeroberfläche).\\
Bis zu zehn Sekunden Latenz vom Eingang der Nachricht bis zur Weiterleitung an die Senke seien hier als \textit{Quasi-Echtzeit} akzeptabel.\\

Als \textit{aktuelle Diskussionen} in der Mailingliste der Sparkbenutzer gelten solche, die innerhalb der letzten etwa 500 Nachrichten geführt wurden. Bei der Bewertung neuer Nachrichten gibt es hier keine Echtzeit-Anforderung. Die Neubewertung bei Eintreffen neuer Nachrichten - höchstens etwa alle 30 Minuten - soll genügen.

\section{Hardwareumgebung}

Als Versuchsumgebung dient ein \gls{cluster} aus vier identischen \gls{worker}n und einem speziellen \gls{master}knoten (Abb. \ref{figure:versuchsaufbau}).

\begin{figure}[h]
	\centering
  \includesvg[pdf]{versuchsaufbau}
	\caption{Hardwareumgebung des Programms zur Tweetanalyse}
	\label{figure:versuchsaufbau}
\end{figure}

Dieser Cluster besteht aus ausschließlich aus leistungsschwacher Hardware. Mit \textit{leistungsschwach} sind Geräte gemeint, deren Leistungsfähigkeit noch deutlich unter aktueller sogenannter \textit{Commodity Hardware} liegt (Vgl. Anhang~\ref{subsec:commodity_servers}).\\

Konkret kommen die folgenden Geräte zum Einsatz:

\paragraph{Worker}
Rasperry Pi 2
\begin{itemize}
	\item CPU: 900MHz Quad-Core ARM Cortex A7
	\item RAM: 1GB SDRAM
	\item Ethernet: 100MBit/s
	\item Festspeicher: SDHC Class 4 Speicherkarte 16GB
\end{itemize}
Als Betriebssystem wird das Debian-Derivat Raspbian\cite{raspbian} 32-Bit genutzt.

\paragraph{Master}
Dell d420
\begin{itemize}
	\item CPU: 1,2 GHz Core2 Duo U2500
	\item RAM: 2GB DDR2 SDRAM
	\item Ethernet: 100MBit/s
	\item Festspeicher: 60GB 4200RPM Hard Drive
\end{itemize}
Als Betriebssystem wird Ubuntu (\cite{ubuntu}) 14.04 32-Bit genutzt.

\paragraph{Netzwerk}
Die Rechner sind mit \gls{rj45} über einen TP-Link TL-SF1008D Switch mit theoretischem maximalem Durchsatz von 100MBit/s vernetzt.

Als Basisdaten für die Leistungsfähigkeit der eingesetzten Hardware werden zusätzliche Tests durchgeführt, deren Ergebnisse in Tabelle \ref{table:network}, Tabelle \ref{table:master_harddrive} und Tabelle \ref{table:master_harddrive} aufgeführt sind.

\begin{table}[ht]
	\centering % used for centering table
	\begin{tabular}{c c c c} % centered columns (4 columns)
	\hline\hline %inserts double horizontal lines
	Worker $\rightarrow$ Worker & Worker $\rightarrow$ Master \\ [0.5ex] % inserts table
	%heading
	\hline % inserts single horizontal line
	94,4 MBit/s & 94,4 MBit/s\\ [1ex] 
	\hline %inserts single line
	\end{tabular}
	\caption{Maximaler Netzwerkdurchsatz{\protect\footnotemark}} % title of Table
	\label{table:network} % is used to refer this table in the text
\end{table}
\footnotetext{Gemessen mit \lstinline|iperf|. Siehe Anhang Listing~\ref{lst:measure_network}}

\begin{table}[ht]
	\centering % used for centering table
	\begin{tabular}{c c c c} % centered columns (4 columns)
	\hline\hline %inserts double horizontal lines
	Operation & Blockgröße (MB) & Durchsatz (MB/s) \\ [0.5ex] % inserts table
	%heading
	\hline % inserts single horizontal line
	Lesen & 1 & 17,2 \\ 
	Lesen & 16 & 22,1 \\
	Lesen & 64 & 31,8 \\
	Lesen & 512 & 31,2 \\
	Schreiben & 1 & 5,0 \\
	Schreiben & 16 & 17,2 \\
	Schreiben & 64 & 26,1 \\
	Schreiben & 512 & 25,8 \\[1ex] 
	\hline %inserts single line
	\end{tabular}
	\caption{Festspeicher Lese-/Schreibdurchsatz dell01 (Master){\protect\footnotemark}} % title of Table
	\label{table:master_harddrive} % is used to refer this table in the text
\end{table}
\footnotetext{Gemessen mit \lstinline|dd|. Siehe Anhang Listing~\ref{lst:measure_harddrive}}

\begin{table}[ht]
	\centering % used for centering table
	\begin{tabular}{c c c c} % centered columns (4 columns)
	\hline\hline %inserts double horizontal lines
	Operation & Blockgröße (MB) & Durchsatz (MB/s) \\ [0.5ex] % inserts table
	%heading
	\hline % inserts single horizontal line
	Lesen & 1 & 66,4 \\ 
	Lesen & 16 & 78,1 \\
	Lesen & 64 & 42,0 \\
	Lesen & 512 & 9,2 \\
	Schreiben & 1 & 17,9 \\ 
	Schreiben & 16 & 18,4 \\
	Schreiben & 64 & 18,4 \\
	Schreiben & 512 & 18,4 \\[1ex] 
	\hline %inserts single line
	\end{tabular}
	\caption{Festspeicher Lese-/Schreibdurchsatz pi00 (Worker)} % title of Table
	\label{table:worker_harddrive} % is used to refer this table in the text
\end{table}

\section{Lösungsskizze}
\paragraph{Wahl des Dateisystems}



\paragraph{Wahl des Cluster-Managers}

Spark läuft in diesem Versuch als alleinige Computeanwendung auf dem Cluster. Es ist also nicht nötig Konkurrenz um Ressourcen zu berücksichtigen. Für diesen Versuch wird daher der Standalone Clustermanager gewählt.\\

\paragraph{Architekturübersicht}\\
\\

Die Architektur der Beispielanwendung teilt die Anwendungslogik in drei Schichten auf. \\
In einer Schicht findet die Verarbeitung eingehender Emails statt und es werden die Relevanz der Begriffe bewertet (\textit{Batch Layer}).
In einer zweiten Schicht werden die Tweets aus einem Datenstrom eingelesen und deren Relevanz anhand der Bewertungen aus der ersten Schicht bewertet (\textit{Streaming Layer}).\\
In der dritten Schicht werden die als relevant eingestuften Emails in einer grafischen Oberfläche dem Benutzer zur Verfügung gestellt (\textit{Presentation Layer}). Diese Schicht gehört nicht zum Spark-Backend und wird für diese Demonstation nicht implementiert.

\begin{figure}[ht!]
	\centering
  \includegraphics[scale=0.7]{data_centric_layers.pdf}
	\caption{Datenzentrierte Sicht auf die Komponenten}
	\label{figure:data_centric_layers}
\end{figure}

\paragraph{Batch Layer}\\
\\

In dieser Schicht wird die Verarbeitung von Emails aus der Spark-User-Mailingliste zu einem Modell von relevanten Wörtern geleistet.\\

Dazu werden eingehende Emails zunächst archiviert und anschließend mithilfe des Korpus aller bisher archivierten Emails und einer Untermenge von \textit{n} zuletzt empfangenen Emails eine Bewertung der vorkommenden Wörtern vorgenommen.\\

Diese Bewertung soll das Maß für die Relevanz eines Wortes in der betrachteten Menge der letzten \textit{n} Emails sein. Um das zu erreichen, wird in mehreren Schritten ein TF-IDF Vektor über die Wörter dieser Nachrichten erzeugt.\\

TF-IDF steht für \textit{Term Frequency - Inverse Document Frequency} (\cite{SparckJones:1988:SIT:106765.106782}). Dieses Verfahren bewertet die Relevanz eines Wortes für einen Text nach der Häufigkeit dieses Wortes in dem Text (\textit{Term Frequency}). Die Bewertung eines Wortes wird jedoch abgeschwächt je häufiger es in einem Textkorpus vorkommt (\textit{Inverse Document Frequency}).\\

Eine Implementation dieses Verfahrens ist in der Spark Standardbibliothek \textit{MLLib} in dem Bereich \textit{Feature Extraction} verfügbar\footnote{https://github.com/apache/spark/tree/branch-1.3/mllib/src/main/scala/org/apache/spark/mllib/feature, abgerufen am 04.06.2015}.\\

In diesem Anwendungsfall gilt:
\begin{itemize}
\item Email-Bodies\footnote{Textbereich einer Email} werden jeweils als Dokumente verarbeitet
\item Das Archiv aller Email-Bodies ist der Textkorpus
\end{itemize}

\begin{figure}[ht!]
	\centering
  \includegraphics[width=\textwidth]{batch_layer.pdf}
	\caption{Innenansicht der Batch-Layer Komponente}
	\label{figure:demo_app_batchlayer}
\end{figure}

\paragraph{Streaming Layer}\\
\\

In dieser Schicht werden die Nachrichten aus dem Twitter-Datenstrom bewertet und gefiltert.\\

Dazu wird über die Spark-Komponente \textit{TwitterUtils}\footnote{TwitterUtils sind Teil der Spark-Standardbibliothek org.apache.spark.streaming.twitter} eine Verbindung über HTTP zu einem Twitter-Endpunkt aufgebaut\footnote{https://dev.twitter.com/streaming/overview/connecting, abgerufen am 01.06.2015}. Über diese Verbindung werden - bei unpriveligiertem Zugriff - etwa 40 Tweets pro Sekunde über einen dauerhaften Datenstrom zur Verfügung gestellt.\\

\begin{figure}[ht!]
	\centering
  \includegraphics[width=\textwidth]{streaming_layer.pdf}
	\caption{Innenansicht der Streaming-Layer Komponente}
	\label{figure:demo_app_streaminglayer}
\end{figure}

In der Komponente RealtimeAnalyzer wurden vor dem Start des Datenstroms Funktionen zur Bewertung einzelner Tweets registriert (VERWEIS?).\\

Die Funktion \lstinline|ScoreTweets| zur Bewertung einzelner Tweets

\[\lstinline|ScoreTweets|: Tweets \longrightarrow \rm I\!R \times Tweets\]
\[tweet \mapsto (score, tweet)\]

wird dabei wie in Listing \ref{lst:tweet_score} dargestellt implementiert:

\begin{lstlisting}[language=Scala,caption={Bewertung von Tweets},label={lst:tweet_score}]
// Split text string into single words
val splitTweets = {
  stream.map(status =>
    (status.getText.split(" "), status)
  )
}

// calculate score for each word, then sum the scores and normalize
val scoredTweets = {
  splitTweets.map(splitTweet => {
    (splitTweet._1.map(word =>
      broadcastScores.value.apply(
         hashingTF.indexOf(word.toLowerCase
           .replaceAll("[^a-zA-Z0-9]", " ")))
     ).sum./(splitTweet._2.getText.split(" ").length),
      splitTweet._2
      )}
  )
}
\end{lstlisting}

Folgendes geschieht Folgendes:
\begin{enumerate}
	\item Extrahieren des Textinhaltes (Metadaten werden ignoriert)
	\item Zerlegen des Textes in einzelne Wörter
	\item Normalisieren der Wörter durch Umwandeln in Kleinbuchstaben und Entfernen von Sonderzeichen
	\item Index der einzelnen Wörter im TF-IDF-Vektor berechnen und dem eingetragenen Score zuweisen (\textit{Map})
	\item Scores aller Wörter eines Tweets summieren (\textit{Reduce})
	\item Normalisieren des Scores per Division durch die Anzahl aller Wörter des Tweets
	\item Rückgabe des Tupels \textit{(Score, Status)}
\end{enumerate}

Anschließend werden die erzeugten Tupel nach der Größe des erreichten Scores gefiltert und die verbleibenden Status-Texte an den TweetSink weitergegeben.\\

\begin{figure}[ht!]
	\centering
  \includegraphics[width=0.9\textwidth]{demo_app_deployment.pdf}
	\caption{Verteilungssicht auf die Demo App}
	\label{figure:demo_app_verteilung}
\end{figure}


\begin{figure}[ht!]
	\centering
  \includegraphics[width=0.9\textwidth]{demo_app_components.pdf}
	\caption{Komponentendiagramm des Demo App Packages}
	\label{figure:demo_app_komponenten}
\end{figure}

\section{Hinweise zur Entwicklung}
Für die Entwicklung hat sich bewährt 

Die Komponenten werden in jeweils eigenen Projekten entwickelt, die sich einzeln auf dem Cluster deployen lassen. Das hat den Vorteil, dass eine einfache Continuous Deployment Pipeline (Abb.~\ref{figure:cd_pipeline}) eingesetzt werden kann, die Änderungen an den jeweiligen Projekten automatisiert auf dem Cluster deployt und so schnellstmögliches Feedback ermöglicht, sowie eine stets lauffähige Codebasis begünstigt.\\

\begin{figure}[ht!]
	\centering
  \includegraphics[width=0.9\textwidth]{Pipeline.pdf}
	\caption{Einfache Continuous Deployment Pipeline}
	\label{figure:cd_pipeline}
\end{figure}

Diese Pipeline ist durch ein \textit{post-receive}-Skript in den jeweiligen Repositories der Komponenten auf dem Gateway-Rechner realisiert (Beispiel im Anhang~\ref{subsec:pipeline}).\\


\section{Ergebnisse und Bewertung}

Zur Beurteilung des Laufzeitverhaltens wird die Anwendung in verschiedenen Konfigurationen des Raspberry-Pi-Clusters gestartet. Dabei wird jeweils das Verhalten der einzelnen Komponenten und des gesamten Systems erfasst und zur späteren Auswertung gespeichert.\\

Die zur Laufzeit erfassten Daten sind
\begin{enumerate}
	\item Systemgrößen auf jedem aktiven Knoten (1 Messpunkt pro Sekunde)
	\subitem CPU Nutzung (User, Idle, System, ...)
	\subitem IO Festplatte (Lesen, Schreiben)
	\subitem Swap (Benutzt, Frei)
	\subitem Speicher (Benutzt, Frei, Cached, ...)
	\subitem IO Netzwerk (Gesendet, Empfangen)
	\item Sparkspezifische Größen (1 Messpunkt alle zwei Sekunden)
	\subitem genutzte Cores
	\subitem aktive Stages
	\subitem parallele Receiver (bei Streaming)
	\subitem u.a.\footnote{Bei den sparkspezifischen Messgrößen gibt es viele weitere, die nicht in die Auswertungen einbezogen werden.}
\end{enumerate}

Als Konfigurationsparameter für die Testläufe werden verwendet
\begin{enumerate}
	\item die Blockgröße des Hadoop-Dateisystems HDFS (32MB, 64MB, 128MB)
	\item der Replikationsfaktor der Blöcke auf HDFS (1, 2, 3, 4)
	\item die Anzahl der Worker (1, 2, 4)
\end{enumerate}

Um eine Vergleichbarkeit der Testläufe untereinander zu erreichen werden folgende Größen festgelegt:
\begin{enumerate}
	\item Größe des Textkorpus: 1,5 GB
	\item Fenstergröße des TF-IDF Vektors: 500 Nachrichten
	\item Erlaubte Cores Pro Executor: 4
	\item Erlaubter Arbeitsspeicher pro Executor: 384 MB
	\item Zeitintervall für die Diskretisierung des Datenstroms (Streaming-Komponente): 5 Sekunden
\end{enumerate}

Die \textbf{Größe des Textkorpus} ergibt sich aus der Überlegung eine Datei zu Verarbeiten, die größer als der Arbeitsspeicher eines einzelnen Workers ist, theoretisch aber noch in den geteilten Speicher von vier Executor-Prozessen passt.\\

Die \textbf{Fenstergröße des TF-IDF Vektors} ist willkürlich gewählt. Der Wert 500 entspricht der Anzahl von Email-Nachrichten aus der Spark-User-Mailingliste.\\

Die erlaubten \textbf{Cores pro Executor} entsprechen genau den Verfügbaren Cores auf einem Worker. Damit ist eine volle Ausnutzung der verfügbaren Rechenleistung gewährleistet.\\

Der erlaubte \textbf{Arbeitsspeicher von 384MB pro Executor} lässt bei 1000MB Gesamtspeicher pro Knoten noch Spielraum für das Betriebssystem, den Worker-Prozess und insbesondere den HDFS Data Node für Caching von Dateiblöcken.\\

Das \textbf{Zeitintervall für die Diskretisierung des Datenstroms} richtet sich nach einem Wert, der für den behandelten Anwendungsfall noch als Echtzeit gelten kann.
Ein höherer Wert würde den notwendigen Puffer erhöhen und vermutlich die Verarbeitungszeit pro Datenelement verringern. Ein niedrigerer Wert würde vermutlich den nötigen Puffer verringern und die relative Verarbeitungszeit eines Datenelementes erhöhen. In der folgenden Analyse der Laufzeitverhaltens wird jedoch deutlich, dass der tatsächliche Wert weitgehend unkritisch für die Stabilität der Komponente ist.\\

Um die Testläufe unter möglichst kontrollierten Bedingungen zu starten, wurde bei jeder Änderung der Konfigurationsparameter das Hadoop-Dateisystem formatiert und der Spark-Cluster zurückgesetzt (inklusive Terminierung und Neustart aller zugehörigen Prozesse).

\subsection{Batch-Komponente}

Die Laufzeitmessung beginnt mit dem Start der ersten Aktion auf einem \gls{RDD} und endet mit der Rückgabe des Relevanzvektors.
Weil die Initialisierung erst zu diesem Zeitpunkt erfolgt, wird der gesamte Prozess von der Kontaktaufnahme zum Cluster und Übermittlung der Tasks bis zur Rückgabe des Ergebnisses gemessen (siehe Listing~\ref{lst:modelbuilder_measuring}).\\

\begin{lstlisting}[language=Scala,caption={Laufzeitmessung},label={lst:modelbuilder_measuring}]
    val documents: RDD[Seq[String]] = sc.textFile(textFile)
      .map(_.toLowerCase)                                // stage 0
      .map(_.split(" ").filter(_.length > 2).toSeq)      // stage 0
    val hashingTF = new HashingTF(1 << 20)
    val tf: RDD[Vector] = hashingTF.transform(documents) // stage 0
    tf.cache() // keep the tf cached because it will be used twice
		
    val beginFeatureExtraction = System.currentTimeMillis()

    val idf = new IDF().fit(tf)                          // stage 0/1
    val tfidf: RDD[Vector] = idf.transform(tf)           // stage 2

    val relevanceVector = tfidf
      .take(docWindowSize)                               // stage 2
      .reduce((vector1, vector2) =>
        addSparseVectors(vector1.asInstanceOf[SparseVector], 
				vector2.asInstanceOf[SparseVector])
      ) // end stage 2, execution ends here

    val finishFeatureExtraction = System.currentTimeMillis()
\end{lstlisting}

Die Zeilen 1-6 in Listing~\ref{lst:modelbuilder_measuring} wurden in die Darstellung aufgenommen, um die Lineage vollständig darzustellen.\\

Der übrige Teil der Anwendung - insbesondere das Abrufen und Prozessieren neu eingegangener Emails - wird nicht berücksichtigt. Bei einem laufenden System sind die dort entstehenden Lasten so gering, dass kein Bedarf für Skalierung besteht.

Tabelle~\ref{table:scaling} zeigt die Laufzeiten der Modelbuilderkomponente bei verschiedenen Konfigurationseinstellungen des Clusters.

\begin{table}[ht]
	\centering % used for centering table
	\begin{tabular}{c c c c} % centered columns (4 columns)
	\hline\hline %inserts double horizontal lines
	Anzahl Worker & Replikationslevel & HDFS Blockgröße (MB) & Laufzeit (Sekunden) \\ [0.5ex] % inserts table
	%heading
	\hline % inserts single horizontal line
	1 & 1 & 32 & 697 \\ % inserting body of the table
	1 & 1 & 64 & 750 \\
	1 & 1 & 128 & 850 (*)\\
	2 & 2 & 32 & 366 \\
	2 & 2 & 64 & 448 \\
	2 & 2 & 128 & 615 \\
	4 & 3 & 32 & 210 \\
	4 & 4 & 32 & 209 (*)\\
	4 & 2 & 64 & 301 \\
	4 & 3 & 64 & 359 \\
	4 & 2 & 128 & 432 \\
	4 & 3 & 128 & 433 \\ [1ex] 
	\hline %inserts single line
	\end{tabular}
	\caption{Skalierungsverhalten des ModelBuilders - mit * sind jeweils die schnellste und langsamste Konfiguration markiert} % title of Table
	\label{table:scaling} % is used to refer this table in the text
\end{table}

Einen besonderen Einfluss auf die Laufzeit hat offenbar die Blockgröße. Bei gleicher Anzahl von Workern und Replikaten verschlechtert sich die Laufzeit in jedem Versuch bei zunehmender Größe. Diese Beobachtung deckt sich mit den in Tabelle~\ref{table:worker_harddrive} dargestellten Eigenschaften des Festspeichers auf den Workern: 
Im Gegensatz zu den Durchsatzraten der mechanischen Festplatte des Masters verschlechtert sich auf den SD-Karten des Workers der Durchsatz bei zunehmender Blockgröße.\\
Ab einer Blockgröße von 128MB ist es zusätzlich nicht mehr möglich vier Blöcke parallel im Arbeitsspeicher des Executor zu halten (384MB) und diese getrennt auf den 4 verfügbaren Cores verarbeiten zu lassen.

\begin{figure}[ht!]
	\centering
  \includegraphics[width=\textwidth]{runtime_vs_blocksize.pdf}
	\caption{Laufzeit der Feature Extraction bei unterschiedlichen HDFS Blockgrößen}
	\label{figure:runtime_vs_blocksize}
\end{figure}

Ein Hinweis auf den Flaschenhals bei der Verarbeitung auf einem einzigen Knoten ist in Abbildung~\ref{figure:1W32B1R_net_cpu} zu erkennen. Die CPU steht unter Volllast, während die Leistung beim Lesen von der SD-Karte mit durchschnittlich 4,3 MB/s deutlich unter dem möglichen Durchsatz bleibt (siehe Tabelle~\ref{table:worker_harddrive}).\\
Netzwerkdurchsatz spielt hier - wie bei einem einzelnen Knoten zu erwarten - offenbar keine Rolle.

\begin{figure}[ht!]
	\centering
  \includegraphics[width=\textwidth]{1W32B1R_net_cpu.pdf}
	\caption{Netzwerk-, SD-Karten und CPU-Auslastung während bei einem Worker und 32MB Blockgröße}
	\label{figure:1W32B1R_net_cpu}
\end{figure}

Betrachtet man die Summe der IO-Durchsätze über sämtliche Knoten lassen sich deutlich die verschiedenen Phasen der Feature-Extraction erkennen. Abbildung~\ref{figure:4W64B2R_io} zeigt das kommentierte Diagramm eines Testlaufs mit 4 Workern, 2 Replikaten und einer HDFS-Blockgröße von 64MB.

\begin{figure}[ht!]
	\centering
  \includegraphics[width=\textwidth]{4W64B2R_io.pdf}
	\caption{Auslastungskurven bei einem Worker und 64MB Blockgröße}
	\label{figure:4W64B2R_io}
\end{figure}

\begin{labeling}{Anmerkung:~}
\item[Anmerkung:] Die Methode \lstinline|treeAggregate|\footnote{https://github.com/apache/spark/blob/branch-1.3/core/src/main/scala/org/apache/spark/rdd/RDD.scala\#L978} stellt einen Spezialfall unter den \gls{rdd}-
Transformationen dar. Sie besteht aus zwei Phasen, wobei in der ersten Phase lokal auf den Partitionen eine Aggregation von Datensätzen durchgeführt wird anschließend über \lstinline|reduce| die partitionsübergreifende Aggregation der bereits partiell aggregierten Datensätze durchgeführt wird.\\
Aus dieser Implementation ergibt sich die Netzwerk-Lastspitze innerhalb von Stage 1 (Abb.~\ref{figure:4W64B2R_io}).
\end{labeling}

\subsection{Echtzeitkomponente}

Einen ersten Blick auf den Zustand einer Spark-Anwendung ermöglicht die Weboberfläche des Treibers.\\

Jede Spark-Applikation startet gemäß der Standardeinstellungen auf dem Host des Treibers einen HTTP-Server, über den verschiedene Daten verfolgt werden können. In Abb.~\ref{figure:realtime_dashboard_stats}) sind die Statistiken einer laufenden Realtime-Komponente dargestellt.\\

In dem betrachteten Fall läuft die Realtime-Komponente mit einem einzelnen Worker, der den Empfänger für den Datenstrom von Twitter startet und das Scoring und Filtern der eingehenden Nachrichten ausführt. Um den Worker nicht für die Modellerzeugung der Batch-Komponente zu blockieren, wurde nur ein Executor mit 2 Cores gewährt.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\textwidth]{bilder/streaming_stats_dashboard.PNG}
	\caption{Spark-Dashboard des Realtime Analyzers - Statistics Tab}
	\label{figure:realtime_dashboard_stats}
\end{figure}

Zum Zeitpunkt des Schnappschusses wurden 6260 Tweets empfangen und verarbeitet. Der letzte Batch enthielt 178 Twitter-Nachrichten (im Durchschnitt sind es etwa 200) und der Median für die Verarbeitungszeit liegt bei 373 Millisekunden (\textit{Total Delay}.\\

Bei einem Zeitfenster von 5 Sekunden (\textit{Batch Interval}) pro Batch gibt es also keinen Hinweis auf Performanceprobleme bei der Verarbeitung.\\

Dieser Verdacht erhärtet sich bei einem Blick auf die CPU-Last des verarbeitenden Workers (Abb.~\ref{figure:str_1W_cpu}). Die durchschnittliche Last über den beobachteten Zeitraum liegt bei 22,5\%. Die Last des Master sogar nur bei 8,1\%.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\textwidth]{str_1W_cpu.pdf}
	\caption{CPU Last eines einzelnen Workers}
	\label{figure:str_1W_cpu}
\end{figure}

Auch die Netzwerklast ist minimal (Abb.~\ref{figure:str_1W_net}). Ab Sekunde 51 liegt die Last des Workers bei durchschnittlich 77 KByte/s. Über den beobachteten Zeitraum von knapp 7 Minuten wurden damit 31.4 Megabyte empfangen. Die Last des Masters liegt noch darunter.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\textwidth]{str_1W_net.pdf}
	\caption{CPU Last eines einzelnen Workers}
	\label{figure:str_1W_net}
\end{figure}

Betrachtet man den Speicherverbrauch (Abb.~\ref{figure:str_mit_mem_pi00}), sieht man, dass sich dieser nach wenigen Sekunden bei etwa 362MB stabilisiert.

\begin{figure}[ht!]
	\centering
	\includegraphics[width=\textwidth]{str_mit_mem_pi00.pdf}
	\caption{CPU Last eines einzelnen Workers}
	\label{figure:str_mit_mem_pi00}
\end{figure}

\subsection{Funktionale Qualität der Lösung}
